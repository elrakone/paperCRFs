% This file was created with JabRef 2.9.2.
% Encoding: Cp1252

@MANUAL{GmbH2012,
  title = {System user manual ARTtrack and TRACKPACK \& DTrack},
  author = {ARTGmbH},
  month = {December},
  year = {2012},
  note = {Version 2.8},
  file = {:C\:\\Users\\Christian\\Master\\Theoretical Part\\references\\DTrack2_User-Manual.pdf:PDF},
  owner = {Christian},
  review = {weiSSer Text als Fake ...
	
	
	
	System user manual
	
	
	ARTtrack©R , TRACKPACK & DTrack©R
	
	
	
	version 2.8
	
	
	December 2012
	
	
	©c 2012 by ART GmbH
	
	
	Contents are subject to
	
	
	change without notice
	
	
	
	dasbetrifft die gesamte seitenbreite der seite des dokumentes etcetcetcetc
	etcetcetcetc etcetcetcetc etcetcetcetc},
  timestamp = {2013.12.14}
}

@ARTICLE{c1,
  author = {Breazeal, Cynthia and Scassellati, Brian},
  title = {Robots that imitate humans},
  journal = {Trends in Cognitive Sciences},
  year = {2002},
  volume = {6(11)},
  pages = {481--487},
  publisher = {Elsevier}
}

@ARTICLE{c15,
  author = {Chevallereau, Christine},
  title = {Time-scaling control for an underactuated biped robot},
  journal = {IEEE Transactions on Robotics and Automation},
  year = {2003},
  volume = {19(2)},
  pages = { 362 - 368},
  doi = {10.1109/TRA.2003.808863},
  issn = {1042-296X},
  keywords = { convergence; cyclic reference path; cyclic reference trajectory tracking;
	dynamic model; five-link planar robot; limit cycle; stability; time-scaling
	control; underactuated biped robot; convergence; legged locomotion;
	limit cycles; position control; robot dynamics; stability; tracking;}
}

@ARTICLE{c13,
  author = {Dariush, Behzad and Gienger, Michael and Arumbakkam, Arjun and Zhu,
	Youding and Jian, Bing and Fujimura, Kikuo and Goerick, Christian},
  title = {Online Transfer of Human Motion to Humanoids},
  journal = {International Journal on Humanoid Robotics},
  year = {2009},
  volume = {6(2)},
  pages = {265-289},
  citedby = {0},
  cites = {0},
  doi = {http://dx.doi.org/10.1142/S021984360900170X},
  researchr = {http://researchr.org/publication/DariushGAZJFG09}
}

@INPROCEEDINGS{c9,
  author = {Dariush, B. and Gienger, M. and Bing Jian and Goerick, C. and Fujimura,
	K.},
  title = {Whole body humanoid control from human motion descriptors},
  booktitle = {IEEE International Conference onRobotics and Automation},
  year = {2008},
  doi = {10.1109/ROBOT.2008.4543616},
  issn = {1050-4729},
  keywords = {Cartesian space;Honda humanoid robot ASIMO;advanced motion control;complex
	robot motion learning;direct robot control;human motion data capture;human
	motion descriptors;humanoid retargeting problem;online robot control;retargeting
	algorithm;retargeting control algorithm;robotics;task space control
	problem;whole body humanoid control;humanoid robots;learning (artificial
	intelligence);motion control;}
}

@INPROCEEDINGS{c16,
  author = {Djoudi, D. and Chevallereau, C.},
  title = {Feet can improve the stability property of a control law for a walking
	robot},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {2006},
  doi = {10.1109/ROBOT.2006.1641873},
  issn = {1050-4729},
  keywords = {biped configuration;cyclic motion;geometric evolution;planar biped;stability
	property;temporal evolution;walking robot;legged locomotion;motion
	control;stability;}
}

@INPROCEEDINGS{c6,
  author = {Do, M. and Azad, P. and Asfour, T. and Dillmann, R.},
  title = {Imitation of human motion on a humanoid robot using non-linear optimization},
  booktitle = {IEEE-RAS International Conference on Humanoid Robots},
  year = {2008},
  doi = {10.1109/ICHR.2008.4756029},
  keywords = {Master Motor Map;goal-directed imitation;human motion imitation;humanoid
	robot;marker-based human motion capture;motor knowledge;nonlinear
	optimization;vision-based markerless human motion capture;gait analysis;humanoid
	robots;image motion analysis;optimisation;robot vision;}
}

@INPROCEEDINGS{Do2008,
  author = {M. Do and P. Azad and T. Asfour and R. Dillmann},
  title = {Imitation of Human Motion on a Humanoid Robot using Nonlinear Optimization},
  booktitle = {IEEE/RAS International Conference on Humanoid Robots (Humanoids)},
  year = {2008},
  pages = {545-552},
  abstract = {In this paper, we present a system for the imitation of basic motor
	primitives. These are learned by clustering and
	
	
	of human motion on a humanoid robot, which is capable of incor- dimensionality
	reduction of visually acquired human motion
	
	
	porating both vision-based markerless and marker-based human data.
	For reproduction, a movement is classified into motor
	
	
	motion capture techniques. Based on the so-called Master Motor
	
	
	Map primitives which are played back sequentially., an interface for
	transferring motor knowledge between
	
	
	embodiments with different kinematics structure, the system is In
	[4] and [5] methods are introduced, where Hidden
	
	
	able to map human movement to a human-like movement on Markov Models
	are trained with a collection of observations
	
	
	the humanoid while preserving the goal-directed characteristics of
	a demonstrated movement. To reproduce a newly observed
	
	
	of the movement. To attain an exact and goal-directed imitation movement,
	the observation is recognized based on a set of
	
	
	of an observed movement, we introduce a reproduction module
	
	
	using non trained models. With the complying model, a generalization-linear
	optimization to maximize the similarity between
	
	
	the demonstrated human movement and the imitation by the of the recognized
	movement is generated.
	
	
	robot. Experimental result using markerless and marker-based Imitation
	learning approaches emphasize the learning and
	
	
	human motion capture data are given. understanding of human behaviour
	by its interpretation by the},
  file = {:C\:\\Users\\Christian.Vassallo\\Università\\MASTER THESIS\\references\\Do2008.pdf:PDF},
  journal = {Humanoid Robots, 2008 8th IEEE/RAS International Conference on},
  owner = {Christian},
  review = {Imitation of Human Motion on a Humanoid Robot
	
	
	using Non-Linear Optimization
	
	
	
	Martin Do, Pedram Azad, Tamim Asfour, Ru¨diger Dillmann
	
	
	University of Karlsruhe, Germany do@ira.uka.de, azad@ira.uka.de, asfour@ira.uka.de,
	dillmann@ira.uka.de
	
	
	
	Abstract—In this paper, we present a system for the imitation of basic
	motor primitives. These are learned by clustering and
	
	
	of human motion on a humanoid robot, which is capable of incor- dimensionality
	reduction of visually acquired human motion
	
	
	porating both vision-based markerless and marker-based human data.
	For reproduction, a movement is classified into motor
	
	
	motion capture techniques. Based on the so-called Master Motor
	
	
	Map primitives which are played back sequentially., an interface for
	transferring motor knowledge between
	
	
	embodiments with different kinematics structure, the system is In
	[4] and [5] methods are introduced, where Hidden
	
	
	able to map human movement to a human-like movement on Markov Models
	are trained with a collection of observations
	
	
	the humanoid while preserving the goal-directed characteristics of
	a demonstrated movement. To reproduce a newly observed
	
	
	of the movement. To attain an exact and goal-directed imitation movement,
	the observation is recognized based on a set of
	
	
	of an observed movement, we introduce a reproduction module
	
	
	using non trained models. With the complying model, a generalization-linear
	optimization to maximize the similarity between
	
	
	the demonstrated human movement and the imitation by the of the recognized
	movement is generated.
	
	
	robot. Experimental result using markerless and marker-based Imitation
	learning approaches emphasize the learning and
	
	
	human motion capture data are given. understanding of human behaviour
	by its interpretation by the
	
	
	
	humanoid. These methods require offline processing and due
	
	
	I. INTRODUCTION to the loss of accuracy as a result of generalization,
	they are
	
	
	
	The interaction between robots and humans is one of often limited
	to simple movements.
	
	
	the main goals in humanoid robotics research. A successful The imitation
	of a complex motion requiring high precision
	
	
	interaction depends on various factors like the acceptance of and
	stability is addressed by approaches dealing with the
	
	
	a humanoid robot by society, its capabilites to act in uncon- pure
	imitation of motion. In contrast to imitation learning, the
	
	
	strained human-centered environments and its communication learning
	of any kind of behaviour is disregarded. Instead, the
	
	
	skills. As a consequence, to raise its acceptance in society, focus
	is on finding a trajectory, which corresponds exactly to
	
	
	a robot needs to adapt human characteristics to its actions the data,
	that a humanoid obtains from a human motion capture
	
	
	and skills. Especially, human-like motion and gestures of a system.
	[6], [7], and [8] present methods for motion imitation,
	
	
	robot are main contributions to its appearance, which has a which
	make use of artificial markers on the humanoid robot
	
	
	strong influence on a user. Hence, under these circumstances as well
	as the demonstrator. For the reproduction of motion,
	
	
	controlling the motion of a robot is a very challenging task corresponding
	marker positions between both subjects are
	
	
	and still a major topic in humanoid robotics research. The minimized
	leading to similar postures. Instead of exploiting
	
	
	most intuitive solution for this problem lies in imitation, where
	marker positions, [9] and [10] calculate the joint angles of a
	
	
	the user adopts the role of a teacher by demonstrating how demonstrators
	posture, which are transferred to the robot for
	
	
	to perform a certain action, while the robot tries to repeat execution.
	Due to joint and velocity constraints, a scaling and
	
	
	this action on the basis of the observation. The benefit of transformation
	process must be performed to obtain a feasible
	
	
	exploiting demonstration is clearly revealed in [1], where an joint
	angle configuration for the robot. In contrast to the
	
	
	anthropomorphic arm is capable of balancing a pole in the mentioned
	motion imitation approaches mentioned above, a
	
	
	first trial after observing a human. The concept of imitation more
	natural way of imitation using the humanoid robots own
	
	
	can be understood in many ways. In [2], imitation of humans stereo
	vision system to record human trajectories by exploiting
	
	
	in the field of robotics is divided into two categories: imitation
	color markers on the demonstrators clothing is presented in
	
	
	learning and motion imitation. [11].
	
	
	
	Imitation learning sets the focus on the understanding of Each of
	these approaches is focused on a specific hu-
	
	
	actions. Following this scheme, which underlies imitation man motion
	capture technique. Since every technique has its
	
	
	learning methods, first, data is collected from multiple ob- advantages
	and drawbacks, in our approach, we propose a
	
	
	servations of a demonstrated action. From this data collection system
	for the imitation of motion within a framework that
	
	
	features are extracted allowing the robot to draw conclusions allows
	integration of various marker-based and markerless
	
	
	on the humans behaviour. Based on the learned behaviour, the human
	motion capture systems and the reproduction on a
	
	
	robot should be able to reproduce a generalized version of the robot.
	This compability leads to a high level of flexibility
	
	
	demonstrated action. and versatility, which opens the system to a
	wide range of
	
	
	
	In [3], a neuroscientific inspired approach is presented, different
	applications from motion analysis to imitation of
	
	
	which solves imitation learning of cyclic motion with a set highly
	complex motions in real-time.},
  timestamp = {2013.12.17}
}

@INPROCEEDINGS{Gouaillier2009,
  author = {Gouaillier, David and Hugel, Vincent and Blazevic, Pierre and Kilner,
	Chris and Monceaux, J\'er\^ome and Lafourcade, Pascal and Marnier,
	Brice and Serre, Julien and Maisonnier, Bruno},
  title = {Mechatronic design of NAO humanoid},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {2009},
  __markedentry = {[user]},
  abstract = {This article presents the mechatronic design of the autonomous humanoid
	robot called NAO that is built by the French company Aldebaran-Robotics.
	With its height of 0.57 m and its weight about 4.5 kg, this innovative
	robot is lightweight and compact. It distinguishes itself from existing
	humanoids thanks to its pelvis kinematics design, its proprietary
	actuation system based on brush DC motors, its electronic, computer
	and distributed software architectures. This robot has been designed
	to be affordable without sacrificing quality and performance. It
	is an open and easy-to-handle platform. The comprehensive and functional
	design is one of the reasons that helped select NAO to replace the
	AIBO quadrupeds in the 2008 RoboCup standard league.},
  keywords = {Brushes , DC motors , Distributed computing , Guidelines , Humanoid
	robots , Infrared sensors , Kinematics , Mechatronics , Pelvis ,
	Robotics and automation},
  owner = {user},
  timestamp = {2013.03.21}
}

@INPROCEEDINGS{c14,
  author = {Hollerbach, John M.},
  title = {Dynamic Scaling of Manipulator Trajectories},
  booktitle = {American Control Conference},
  year = {1983}
}

@BOOK{Khalil2002,
  title = {Modeling, Identification and Control of Robots},
  publisher = {Taylor \& Francis, Inc.},
  year = {2002},
  author = {Khalil, Wisama and Dombre, Etienne},
  address = {Bristol, PA, USA},
  edition = {3rd},
  isbn = {1560329831},
  owner = {Christian},
  timestamp = {2014.01.29}
}

@INPROCEEDINGS{c7,
  author = {Seungsu Kim and ChangHwan Kim and Bumjae You and Sangrok Oh},
  title = {Stable whole-body motion generation for humanoid robots to imitate
	human motions},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2009},
  doi = {10.1109/IROS.2009.5354271},
  keywords = {dynamic mapping;human foot scaling;human motion imitation;humanoid
	robots;kinematic mapping;online balancing controllers;whole-body
	motion generation;zero moment point trajectory;controllers;humanoid
	robots;motion control;position control;robot dynamics;robot kinematics;}
}

@INPROCEEDINGS{c11,
  author = {Matsubara, T. and Uchikata, A. and Morimoto, J.},
  title = {Spatio-temporal Synchronization of Periodic Movements by Style-phase
	Adaptation : Application to Biped Walking},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {2012},
  doi = {10.1109/ICHR.2008.4755984},
  keywords = {Cartesian control;balancing controller;direct marker control;hidden
	Markov models;human motion recognition;humanoid robot;joint position
	controllers;marker point measurements;motion capture;robot dynamics;robot
	motion;translational springs;hidden Markov models;humanoid robots;motion
	control;path planning;position control;robot dynamics;}
}

@INPROCEEDINGS{Karthick2012,
  author = {Munirathinam, K. and Sakka, S. and Chevallereau, C.},
  title = {Dynamic motion imitation of two articulated systems using nonlinear
	time scaling of joint trajectories},
  booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
  year = {2012},
  issn = {1050-4729},
  keywords = {biped configuration;cyclic motion;geometric evolution;planar biped;stability
	property;temporal evolution;walking robot;legged locomotion;motion
	control;stability;}
}

@INPROCEEDINGS{c4,
  author = {Nakaoka, S. and Nakazawa, A. and Yokoi, K. and Hirukawa, H. and Ikeuchi,
	K.},
  title = {Generating whole body motions for a biped humanoid robot from captured
	human dances},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {2003},
  doi = {10.1109/ROBOT.2003.1242196},
  issn = {1050-4729},
  keywords = { Japanese folk dance; Jongara-bushi; balance control; biped humanoid
	robot; human dance motions; human dances; joint angle sequence; mechanical
	constraints; motion capturing system; openHRP dynamics simulator;
	primitive motions; robot arm motions; robot leg motions; waist trajectory;
	whole body motion generation; zero moment point; humanities; image
	motion analysis; mobile robots; motion control; position control;
	robot dynamics;}
}

@INPROCEEDINGS{c3,
  author = {Nakazawa, A. and Nakaoka, S. and Ikeuchi, K. and Yokoi, K.},
  title = {Imitating human dance motions through motion structure analysis},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2002},
  doi = {10.1109/IRDS.2002.1041652},
  keywords = { PC clusters; cameras; dance motion generation; dynamic balancing
	technique; end-effector trajectories; human dance motion imitation;
	humanoid robots; inverse-kinematics; motion capture system; motion
	elements; motion primitives; motion sequence; motion structure analysis;
	visual observation; humanities; image motion analysis; image segmentation;
	image sequences; learning by example; legged locomotion;}
}

@INPROCEEDINGS{c10,
  author = {Ott, C. and Dongheui Lee and Nakamura, Y.},
  title = {Motion capture based human motion recognition and imitation by direct
	marker control},
  booktitle = {IEEE-RAS International Conference on Humanoid Robots},
  year = {2008},
  doi = {10.1109/ICHR.2008.4755984},
  keywords = {Cartesian control;balancing controller;direct marker control;hidden
	Markov models;human motion recognition;humanoid robot;joint position
	controllers;marker point measurements;motion capture;robot dynamics;robot
	motion;translational springs;hidden Markov models;humanoid robots;motion
	control;path planning;position control;robot dynamics;}
}

@INPROCEEDINGS{c2,
  author = {Pollard, N.S. and Hodgins, J.K. and Riley, M.J. and Atkeson, C.G.},
  title = {Adapting human motion for the control of a humanoid robot},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {2002},
  doi = {10.1109/ROBOT.2002.1014737},
  issn = { },
  keywords = { ATR; Sarcos; gimbal lock; humanoid robot; joint angle; joint velocity;
	motion control; trajectory tracking; upper body gestures; legged
	locomotion; mobile robots; motion control; tracking;}
}

@INPROCEEDINGS{c18,
  author = {Saegusa, Ryo and Metta, Giorgio and Sandini, Giulio and Sakka, Sophie},
  title = {Active motor babbling for sensorimotor learning},
  booktitle = {IEEE International Conference on Robotics and Biomimetics},
  year = {2008},
  owner = {user},
  timestamp = {2013.03.22}
}

@INCOLLECTION{Shoemake1994,
  author = {Shoemake, Ken},
  title = {Euler Angle Conversion},
  booktitle = {Graphics Gems IV},
  publisher = {Academic Press Professional, Inc.},
  year = {1994},
  editor = {Heckbert, Paul S.},
  pages = {222--229},
  address = {San Diego, CA, USA},
  owner = {Christian},
  timestamp = {2013.12.17},
  url = {http://dl.acm.org/citation.cfm?id=180895.180914}
}

@INPROCEEDINGS{c5,
  author = {Suleiman, W. and Yoshida, E. and Kanehiro, F. and Laumond, J.-P.
	and Monin, A.},
  title = {On human motion imitation by humanoid robot},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = {2008},
  doi = {10.1109/ROBOT.2008.4543619},
  issn = {1050-4729},
  keywords = {dynamics algorithm;gradient function;human captured motion;human motion
	imitation;humanoid robot;optimization problem;gradient methods;humanoid
	robots;motion control;optimisation;}
}

@INPROCEEDINGS{c12,
  author = {Sung-Kyun, K. and Seokmin, H. and Doik, K. and Yonghwan, O. and Bum-Jae,
	Y. and Sang-Rok Oh},
  title = {Online footprint imitation of a humanoid robot by walking motion
	parameterization},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2010},
  doi = {10.1109/IROS.2010.5650349},
  issn = {2153-0858},
  keywords = {MAHRU-R;human independent foot motion;human walking motion parameterisation;human-like
	motion;humanoid robot;motion capture device;online footprint imitation;teleoperation;walking
	trajectory;humanoid robots;legged locomotion;motion control;parameter
	estimation;position control;telerobotics;}
}

@ARTICLE{Ude2004,
  author = {Ude, Ales and Atkeson, Christopher G. and Riley, Marcia},
  title = {Programming full-body movements for humanoid robots by observation},
  journal = {Robotics and Autonomous Systems},
  year = {2004},
  volume = {47},
  pages = {93-108},
  number = {2-3},
  abstract = {The formulation and optimization of joint trajectories for humanoid
	robots is quite different from this same task for standard robots
	because of the complexity of humanoid robots’ kinematics and dynamics.
	In this paper we exploit the similarity between human motion and
	humanoid robot motion to generate joint trajectories for humanoids.
	In particular, we show how to transform human motion information
	captured by an optical tracking device into a high dimensional trajectory
	for a humanoid robot. We propose an automatic approach to relate
	humanoid robot kinematic parameters to the kinematic parameters of
	a human performer. Based on this relationship we infer the desired
	trajectories in robot joint space. B-spline wavelets are utilized
	to efficiently represent the trajectories. The density of the basis
	functions on the time axis is selected automatically. Large-scale
	optimization techniques are employed to solve the underlying computational
	problems efficiently. We applied our method to the task of teaching
	a humanoid robot how to make various naturally looking movements.},
  file = {Ude2004.pdf:Ude2004.pdf:PDF},
  keywords = {Humanoid robots; Joint trajectories; Optimization},
  owner = {sakka},
  timestamp = {2008.03.07}
}

@INPROCEEDINGS{Ude2000,
  author = {Ude, Ales and Man, Curtis and Riley, Marcia and Atkeson, Christopher
	G.},
  title = {Automatic Generation of Kinematic Models for the Conversion of Human
	Motion Capture Data into Humanoid Robot Motion},
  booktitle = {IEEE-RAS International Conference on Humanoid Robots},
  year = {2000},
  abstract = {Human motion capture is a promising technique for the generation of
	humanoid robot motions. To convert human motion into humanoid robot
	motion, we need to relate the humanoid robot kinematics to the kinematics
	of a human performer. In this paper we propose an automatic approach
	for scaling of humanoid robot kinematic parameters to the kinematic
	parameters of a human performer. The kinematic model is constructed
	directly from the motion capture data without manual measurements.
	We discuss the use of the resulting kinematic model for the generation
	of humanoid robot motions based on teh observed human motions. The
	results of the proposed technique on real human motion capture data
	are presented.},
  file = {Ude2000.pdf:Ude2000.pdf:PDF},
  owner = {sakka},
  timestamp = {2008.03.07}
}

@INPROCEEDINGS{c8,
  author = {Yamane, K. and Hodgins, J.},
  title = {Simultaneous tracking and balancing of humanoid robots for imitating
	human motion capture data},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = {2009}
}

